---
title: "Expression Report"
author: "Alfredo Rago"
date: "`r format(Sys.time(), '%d %b %Y')`"
output: html_document
---
## Data cleaning and overview

```{r setup, include=F}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, cache = TRUE)
# Tidyverse things
library(tidyverse)
library(magrittr)
library(here)
# Read experiment data
library(SummarizedExperiment)
# Improved plots
library(ggrepel)
library(dendextend)
# Pretty markdown tables
library(knitr)
library(kableExtra)
library(formattable)
```
```{r import_data, message=FALSE, warning=FALSE, include=FALSE}
# Replace with python input after finalization
abundance_matrix <- 
  here("results/tximeta/gene_data.Rdata") %>% 
  readRDS(.) %>% 
  assay(., 2) %>% 
  ceiling(.) %>% 
  DESeq2::vst() %>% 
  t()
```
```{r filter_data, message=FALSE, warning=FALSE, include=FALSE}
abundance_threshold = 6
min_samples = 2

good_genes <- apply(
  X = abundance_matrix, 
  MARGIN = c(1,2), 
  FUN = function(x){ifelse(x < abundance_threshold, 0, x)}
) %>% 
  WGCNA::goodSamplesGenes(
    datExpr = ., 
    minNSamples = min_samples)

abundance_matrix_filtered <- abundance_matrix[,which(good_genes$goodGenes)]
```

This report includes the first overview of the data from the 2D organoid projects.
Since we did not detect any mycoplasma contamination we did not remove any sample, nor reads.
The full reproducible workflow up to this point is available at https://github.com/alfredorago/organoids-probio.
Note: the repository is private so please ask to be added as a collaborator if you want to inspect the workflow in detail.

The number of total annotated genes after Salmon quantification and matching with the human genome data via tximeta are `r ncol(abundance_matrix)`. 
We threshold genes by setting all counts lower than `r abundance_threshold` to 0, and removing all genes which are not expressed in at least `r min_samples` samples.
This selection procedure discards `r sum(good_genes$goodGenes == FALSE)` genes, so all further analyses consider only `r sum(good_genes$goodGenes)` genes.


## PCA

```{r PCA, echo=FALSE}
pca_data <- prcomp(x = abundance_matrix_filtered, center = T, scale. = T)

pca_percent_variance <- 
  summary(pca_data) %$% 
  importance[2,] %>% 
  multiply_by(., 100) %>% 
  round(digits = 2) %>% 
  paste0("PC", 1:length(.), " (", ., "% variance)")

odd_samples = 
  which(pca_data$x[,2] < -40) %>% 
  as.integer() 

pca_x <- pca_data$x %>% 
  as_tibble() %>% 
  rownames_to_column(var = "sample_ID")

pca_scatterplot <- ggplot(
  data = pca_x, 
  aes(x = PC1, y = PC2, label = sample_ID, col = sample_ID %in% odd_samples)
) + 
  geom_point() +
  geom_text_repel() +
  ggtitle(label = "PCA of samples annotated by gene expression") +
  xlab(label = pca_percent_variance[1]) +
  ylab(label = pca_percent_variance[2]) +
  labs(col = 'Odd Samples')
```

### Variance distribution

We perform a quick PCA analysis to detect if there are any patterns in our dataset and whether there are any outliers.
We need 22(!) principal components to describe 95% of the variance in our dataset. 
This shows that there are several independent sources of variation between our samples and is a good thing. 
With just 5 principal components we can already describe 80% of our dataset, which seems like a reasonable amount of precision.
With 10 PCs we can push the precision to almost 90% of the total variance.

```{r pca_variance, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
tibble(
  PC = 1:nrow(pca_data$x) %>% str_pad(string = ., 2, pad = "0") %>% paste("PC", .),
  Variance = summary(pca_data) %$% importance[2,] %>% multiply_by(., 100) %>% round(digits = 2),
  Cumulative_Variance = cumsum(Variance) 
) %>%
  filter(.,
         Cumulative_Variance < 90
  ) %>% 
  mutate(., 
         Variance = Variance %>% color_bar("lightgreen")(.),
         Cumulative_Variance = Cumulative_Variance %>% color_bar("lightblue")(.)
  ) %>% 
  kable("html", escape = F, align = 'r', digits = 3, longtable = F) %>%
  kable_styling(c("hover", "striped"), full_width = T)
```

### Global patterns

I look at the data using the first 5 PCs. The samples separate cleanly in a set of compact clusters, which suggests that we have strong differences between some treatments at least.
PC 5 provides almost no separation between clusters, so we can likely focus on the first 4 PCs.
I am slightly suspicious of the samples in blue, which separate in a rather scattered cluster alongside PC 2 and 3, and show extreme values alongside all other PCs as well.

```{r correlation_scatterplot, echo=FALSE, fig.height=8, fig.width=10, message=FALSE}
GGally::ggpairs(data = pca_x, columns = 2:6, aes(col = sample_ID %in% odd_samples, label = sample_ID), columnLabels = pca_percent_variance[1:5]) + theme_minimal()
```

## Hierarchical clustering

I also compare the samples via hierarchical clustering, using euclidean distance between them in gene-space and single-spanning trees.
In other words, we group the samples that most look like each other in their gene expression profiles.
The "odd" samples look widely distributed across the tree, which I would not expect from true outliers. 
As soon as we get the rest of the metadata we can look for signal from our treatments in the hierarchical tree and/or create a heatmap.

```{r hclust, echo=FALSE, fig.width=12}
expr_hclust <- 
  str_extract(string = row.names(abundance_matrix_filtered), pattern = "[:digit:]{1,2}$") %>% 
  str_pad(string = ., 2, pad = "0") %>% 
  set_rownames(x = abundance_matrix_filtered, value = .) %>% 
  dist(x = ., method = 'euclidean') %>% 
  hclust(d = ., method = 'single')

expr_dend <- as.dendrogram(expr_hclust)
labels_colors(expr_dend) <-
  ifelse(
    labels(expr_dend) %in% str_pad(string = odd_samples, 2, pad = "0"),
    "purple",
    "darkblue"
  )

plot(
  expr_dend,
  main = "Euclidean distance between samples"
)
```
